{"cells":[{"source":"Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.\n\nBy fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.\n\n## The Data\n\n<img src=\"x-rays_sample.png\" align=\"center\"/>\n&nbsp\n\nYou have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders. \n\nThere are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library. ","metadata":{},"id":"85dc467a-5830-44c0-ab74-435be0e5593c","cell_type":"markdown"},{"source":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":2774,"lastExecutedAt":1738944883942,"lastExecutedByKernel":"f589fdae-c6dd-406a-8607-bd2f48df2b75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","outputsMetadata":{"0":{"height":526,"type":"stream"}}},"id":"0f522b79-2a5a-4472-adb9-0d924870bfa1","cell_type":"code","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torch in /home/repl/.local/lib/python3.10/site-packages (2.6.0)\nRequirement already satisfied: torchvision in /home/repl/.local/lib/python3.10/site-packages (0.21.0)\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.10/site-packages (1.6.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.3.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/repl/.local/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/repl/.local/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/repl/.local/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/repl/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/repl/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/repl/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/repl/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/repl/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/repl/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/repl/.local/lib/python3.10/site-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/repl/.local/lib/python3.10/site-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/repl/.local/lib/python3.10/site-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /home/repl/.local/lib/python3.10/site-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /home/repl/.local/lib/python3.10/site-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.3.0)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.10/site-packages (from torchmetrics) (0.12.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (69.5.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(69420)\nnp.random.seed(69420)\nrandom.seed(69420)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1738944883996,"lastExecutedByKernel":"f589fdae-c6dd-406a-8607-bd2f48df2b75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(69420)\nnp.random.seed(69420)\nrandom.seed(69420)"},"id":"cb1bedee-bcd5-4c80-a5ed-93df89af0295","cell_type":"code","execution_count":10,"outputs":[]},{"source":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1738944884047,"lastExecutedByKernel":"f589fdae-c6dd-406a-8607-bd2f48df2b75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"},"id":"dd91680d-cb63-4876-9a51-4ee6bb250c7d","cell_type":"code","execution_count":11,"outputs":[]},{"source":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1738944884095,"lastExecutedByKernel":"f589fdae-c6dd-406a-8607-bd2f48df2b75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"},"id":"0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f","cell_type":"code","execution_count":12,"outputs":[]},{"source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\n\n# Initialize the model with pre-trained weights\nweights = models.ResNet18_Weights.DEFAULT\nmodel = models.resnet18(weights=weights)\n\n# Modify the final layer to match the number of classes in the dataset\nnum_classes = len(train_dataset.classes)\nmodel.fc = nn.Linear(model.fc.in_features, num_classes)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# Move the model to the GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n\n# Save the trained model\ntorch.save(model.state_dict(), 'resnet18_chestxrays.pth')","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":311,"type":"stream"},"1":{"height":227,"type":"stream"}}},"id":"c99cf95b-83f3-49e4-9777-4e70736452d8","cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/100, Loss: 0.5673511475324631\nEpoch 2/100, Loss: 0.1481863111257553\nEpoch 3/100, Loss: 0.07122110202908516\nEpoch 4/100, Loss: 0.033084576949477196\nEpoch 5/100, Loss: 0.012563369702547789\nEpoch 6/100, Loss: 0.007501395419239998\nEpoch 7/100, Loss: 0.0049491263926029205\nEpoch 8/100, Loss: 0.003933176398277283\nEpoch 9/100, Loss: 0.001745008456055075\nEpoch 10/100, Loss: 0.0012855480890721083\nEpoch 11/100, Loss: 0.0009064339101314545\nEpoch 12/100, Loss: 0.0012319103989284486\nEpoch 13/100, Loss: 0.0006734683702234179\nEpoch 14/100, Loss: 0.0006155104347271845\n"}]},{"source":"### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model.","metadata":{},"id":"70761893-e66f-40fe-8862-dac9b18a13ab","cell_type":"markdown"},{"source":"#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists to store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        # Forward pass\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n        # Extend the lists with predictions and labels\n        all_preds.extend(preds.squeeze().tolist())  # Squeeze to match the shape\n        all_labels.extend(labels.tolist())  # No need to unsqueeze\n\n# Convert lists back to tensors\nall_preds = torch.tensor(all_preds).squeeze()  # Ensure the shape matches\nall_labels = torch.tensor(all_labels).squeeze()  # Ensure the shape matches\n\n# Ensure predictions and labels have the same shape\nif all_preds.ndim > 1 and all_preds.shape[1] == 1:\n    all_preds = all_preds.squeeze(1)\n\n# Fix: Ensure predictions are in the same shape as labels\nif all_preds.ndim > 1 and all_preds.shape[1] == 2:\n    all_preds = all_preds[:, 1]  # Take the second column which represents the positive class\n\n# Calculate accuracy and F1 score\ntest_acc = accuracy_metric(all_preds, all_labels).item()\ntest_f1 = f1_metric(all_preds, all_labels).item()\n\nprint(f\"Test Accuracy: {test_acc}\")\nprint(f\"Test F1 Score: {test_f1}\")","metadata":{"executionCancelledAt":null,"executionTime":1906,"lastExecutedAt":1738944843647,"lastExecutedByKernel":"f589fdae-c6dd-406a-8607-bd2f48df2b75","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists to store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        # Forward pass\n        outputs = model(inputs)\n        preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n        # Extend the lists with predictions and labels\n        all_preds.extend(preds.squeeze().tolist())  # Squeeze to match the shape\n        all_labels.extend(labels.tolist())  # No need to unsqueeze\n\n# Convert lists back to tensors\nall_preds = torch.tensor(all_preds).squeeze()  # Ensure the shape matches\nall_labels = torch.tensor(all_labels).squeeze()  # Ensure the shape matches\n\n# Ensure predictions and labels have the same shape\nif all_preds.ndim > 1 and all_preds.shape[1] == 1:\n    all_preds = all_preds.squeeze(1)\n\n# Fix: Ensure predictions are in the same shape as labels\nif all_preds.ndim > 1 and all_preds.shape[1] == 2:\n    all_preds = all_preds[:, 1]  # Take the second column which represents the positive class\n\n# Calculate accuracy and F1 score\ntest_acc = accuracy_metric(all_preds, all_labels).item()\ntest_f1 = f1_metric(all_preds, all_labels).item()\n\nprint(f\"Test Accuracy: {test_acc}\")\nprint(f\"Test F1 Score: {test_f1}\")","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960","cell_type":"code","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"Test Accuracy: 0.550000011920929\nTest F1 Score: 0.6896551847457886\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}